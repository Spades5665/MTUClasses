{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a2 - python - CS4821\n",
    "\n",
    "This assignment will cover topics from data, data preprocessing, and classification.\n",
    "\n",
    "Make sure that you keep this notebook named as \"a2-4821.ipynb\" \n",
    "\n",
    "Submit the zip-file created after running your notebook on the Linux lab machines.\n",
    "\n",
    "Any other packages or tools, outside those listed in the assignments or Canvas, should be cleared\n",
    "by Dr. Brown before use in your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Q0 - Setup\n",
    "\n",
    "The following code looks to see whether your notebook is run on Gradescope (GS), Colab (COLAB), or the linux Python environment you were asked to setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re \n",
    "import os\n",
    "import platform \n",
    "import sys \n",
    "\n",
    "# flag if notebook is running on Gradescope \n",
    "if re.search(r'amzn', platform.uname().release): \n",
    "    GS = True\n",
    "else: \n",
    "    GS = False\n",
    "\n",
    "# flag if notebook is running on Colaboratory \n",
    "try:\n",
    "  import google.colab\n",
    "  COLAB = True\n",
    "except:\n",
    "  COLAB = False\n",
    "\n",
    "# flag if running on Linux lab machines. \n",
    "cname = platform.uname().node\n",
    "if re.search(r'(guardian|colossus|c28|coc-15954-m)', cname):\n",
    "    LLM = True \n",
    "else: \n",
    "    LLM = False\n",
    "\n",
    "print(\"System: GS - %s, COLAB - %s, LLM - %s\" % (GS, COLAB, LLM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Notebook Setup \n",
    "\n",
    "It is good practice to list all imports needed at the top of the notebook. You can import modules in later cells as needed, but listing them at the top clearly shows all which are needed to be available / installed.\n",
    "\n",
    "If you are doing development on Colab, the otter-grader package is not available, so you will need to install it with pip (uncomment the cell directly below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Only uncomment if you developing on Colab \n",
    "# if COLAB == True: \n",
    "#     print(\"Installing otter:\")\n",
    "#     !pip install otter-grader==4.2.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Import standard DS packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import statistics\n",
    "import textwrap\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import tree        # decision tree classifier\n",
    "from sklearn import neighbors   # knn classifier\n",
    "from sklearn import naive_bayes # naive bayes classifier \n",
    "from sklearn import metrics     # performance evaluation metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing \n",
    "from sklearn import pipeline\n",
    "# import graphviz, pydotplus\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score,mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Package for Autograder \n",
    "import otter \n",
    "grader = otter.Notebook()\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvDdQg2KBbfa"
   },
   "source": [
    "# Q1 - Exploratory Data Analysis \n",
    "\n",
    "Consider the `movies` data set available on Canvas. The data set is made up of over 600 randomly selected movies, released before 2016, with information extracted from IMDB and Rotten Tomatoes. A code book on the variables is also provided.\n",
    "\n",
    "You should explore the files a bit in a text editor to understand the format. The variables are made up of different types: nominal, ordinal, numeric, etc. We will refer to the different variables by their column / codebook names.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "# *Missing Data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Q1(a) - Examine data for loading \n",
    "\n",
    "Look at the `movies` data set.  Is there any missing data in the `movies` data set? \n",
    "If so, how is it encoded? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data is encoded as:   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Q1(b) - Load the data\n",
    "\n",
    "Load the movies data into a DataFrame `q1movies`.  Is there any missing data in the `movies` data set? \n",
    "If yes, make sure to encode those missing values when reading the data in pandas `read_csv` function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in movies data with pandas \"read_csv\" function\n",
    "#  Use column names from the original csv file \n",
    "\n",
    "q1movies = pd.read_csv(...)\n",
    "\n",
    "q1movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Q1(c) - Missing data \n",
    "\n",
    "We want to understand where (which variable) and how much data is missing (for each variable the percentage of rows). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a Data.Series that has the percentage of missing data for each \n",
    "#  attribute in the movies data set.\n",
    "miss_data = ... \n",
    "\n",
    "miss_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Q1(d) - Clean data \n",
    "\n",
    "We want to clean up data with respect to the missing values. \n",
    "\n",
    "Ignore any missing values in the `studio`, `dvd_rel_year`, `dvd_rel_month`, `dvd_rel_day`, and all variables including and listed after `best_pic_nom`. For other missing values, remove the sample that contains the missing value.\n",
    "\n",
    "Save the resulting DataFrame in the `movies` variable.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Ignore missing values in \"studio\", \"dvd_rel_year\", \"dvd_rel_month\", \n",
    "#   \"dvd_rel_day\", and all varaibles including and after \"best_pic_nom\"\n",
    "# For other missing values, remove the sample that contains the missing value. \n",
    "\n",
    "movies = ...\n",
    "\n",
    "movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Q1(e) - Attribute Types\n",
    "\n",
    "For the following variables, state the attribute type: 1- *nominal*, 2- *ordinal*, 3- *interval*, or 4- *ratio*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type_genre = ...\n",
    "type_runtime = ...\n",
    "type_mpaa_rating = ...\n",
    "type_studio = ...\n",
    "type_thtr_rel_month = ...\n",
    "type_imdb_rating = ...\n",
    "type_audience_score = ...\n",
    "type_best_pic_win = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# *Summary Statistics*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Q1(f) - Statistics, part 1\n",
    "\n",
    "For the following variables, report out a five number summary:\n",
    "`audience_score` and `imdb_rating`\n",
    "\n",
    "Store results in a DataFrame: `q1f`\n",
    "\n",
    "*Hint:* consider using the `describe` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Report five number summary for variables `audience_score` and `imdb_rating` in \n",
    "#  a DataFrame \"q1f\" \n",
    "#  Rows should represent: min, Q1 - 25%, Q2 - 50%, Q3 - 50%, max \n",
    "#  Columns should be `audience_score` then `imdb_rating` \n",
    "\n",
    "q1f = ...\n",
    "\n",
    "q1f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Q1(g) - Statistics, part 2 \n",
    "\n",
    "Report the mean, median, and mode of `critics_score` and `runtime` to the given variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Report mean, median and mode of \"critics_score\" and \"runtime\" \n",
    "\n",
    "# For critics_score- \n",
    "q1g_cs_mean = ...\n",
    "q1g_cs_median = ...\n",
    "q1g_cs_mode = ...\n",
    "\n",
    "# For runtime- \n",
    "q1g_r_mean = ...\n",
    "q1g_r_median = ...\n",
    "q1g_r_mode = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Q1(h) - Statistics, part 3\n",
    "\n",
    "Report the first quartile, 37th percentile, third quartile, and 83rd percentile\n",
    "for `critics_score` and `runtime` and assign it to the given variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Report first quartile, 31st percentile, third quartile, and 90th percentile\n",
    "#  of \"critics_score\" and \"runtime\" \n",
    "\n",
    "# For critics_score- \n",
    "q1h_cs_q1 = ...\n",
    "q1h_cs_p37 = ...\n",
    "q1h_cs_q3 = ...\n",
    "q1h_cs_p83 = ...\n",
    "\n",
    "# For runtime- \n",
    "q1h_r_q1 = ...\n",
    "q1h_r_p37 = ...\n",
    "q1h_r_q3 = ...\n",
    "q1h_r_p83 = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "# *Visualizations* \n",
    "\n",
    "## Q1(i) Visualization: Single Variable \n",
    "\n",
    "I highly encourage looking at the [Fundamentals of Visualization](https://clauswilke.com/dataviz/index.html) reference book to guide in the creation of “good” visualizations requested below.\n",
    "\n",
    "\n",
    "Create a bar plot for the `critics_rating` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create bar plot for \"critics_rating\" \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Q1(j) Visualization: Two Variables \n",
    "\n",
    "Create a violin plot for `imdb_rating` grouped by `mpaa_rating` (sorted by mpaa rating, where 'Unrated' is last).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a violin plot for `imdb_rating` grouped by `mpaa_rating` (sorted)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Q1(k) Visualization: Multiple variables\n",
    "\n",
    "Create a stacked bar chart to display the proportion of wins (nominations) for the 5 `best_*` variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a stacked bar chart to display the proportion of wins (nominations) \n",
    "#   for the 5 `best_*` variables.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Q1(l) Visualization: Two Variables \n",
    "\n",
    "Create an overlapping density plot for `critics_score` grouped by `audience_rating`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create overlapping density plot\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Q1(m) Visualization: Multiple variables \n",
    "\n",
    "Create a small multiples (or faceted) scatter plot of `imdb_rating` (y-axis) against `runtime` (x-axis) for each `critics_rating`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a small multiples (or faceted) scatter plot of `imdb_rating` vs. \n",
    "#   `runtime` for each `critics_rating`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Q1(bonus)   \n",
    "\n",
    "Create a small multiples (or faceted) scatter plot of `imdb_rating` vs. `runtime` for each of the top 4 `genre` (in order of most frequent), colored with the `critics_rating`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a small multiples (or faceted) scatter plot of `imdb_rating` vs. \n",
    "#   `runtime` for each of the top 4 `genre`, colored by the `critics_rating`\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# Q2 - Data Preprocessing\n",
    "\n",
    "Let's make sure you become familiar using the scaling functions that are available in standard libraries: \n",
    "\n",
    "* Python: `MinMaxScaler` and `StandardScaler` or scale in `sklearn.preprocessing`\n",
    "\n",
    "Here you will use the `MinMaxScaler`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train/test data \n",
    "q2train = pd.DataFrame({'x1': [20, 37, 40, 60, 85, 120], \n",
    "                        'x2': [-10, -8, 52, 3, 18, 23]})\n",
    "q2test = pd.DataFrame({'x1': [42, 58, 101], 'x2': [-8, 42, 54]})\n",
    "\n",
    "# Setup a scaler, fit and transform the training data \n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "q2outA = scaler.fit_transform(q2train)\n",
    "print(q2outA)\n",
    "\n",
    "\n",
    "# Setup a MinMaxScaler with default range parameters\n",
    "# fit the scaler to the training data, transform it, and transform the test data\n",
    "scaler = ...\n",
    "q2outBtrain = ...\n",
    "q2outBtest = ...\n",
    "print(q2outBtrain)\n",
    "print(q2outBtest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Q3 - Data Preprocessing\n",
    "\n",
    "Let's make sure you become familiar using the scaling functions that are available in standard libraries: \n",
    "\n",
    "* Python: `MinMaxScaler` and `StandardScaler` or scale in `sklearn.preprocessing`\n",
    "\n",
    "Here you will use the `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train/test data \n",
    "# q2train = pd.DataFrame({'x1': [20, 37, 40, 60, 85, 120], \n",
    "#                       'x2': [-10, -8, 52, 3, 18, 23]})\n",
    "# q2test = pd.DataFrame({'x1': [42, 58, 101], 'x2': [-8, 42, 54]})\n",
    "\n",
    "\n",
    "# Setup a Standard scaler, fit and transform the training data \n",
    "scaler = preprocessing.StandardScaler()\n",
    "q3outA = scaler.fit_transform(q2train)\n",
    "print(q3outA)\n",
    "\n",
    "# use StandardScaler\n",
    "# fit the scaler to the training data, transform it, and transform the test data\n",
    "scaler = ...\n",
    "q3outBtrain = ...\n",
    "q3outBtest = ...\n",
    "print(q3outBtrain)\n",
    "print(q3outBtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "# Q4 - Performance Metrics \n",
    "\n",
    "Write a function to calculate: \n",
    "(a) true positive rate,\n",
    "(b) false positive rate, \n",
    "(c) accuracy, and \n",
    "(d) Matthews Correlation Coefficient (MCC). \n",
    "\n",
    "You can make use of `sklearn.metrics` functions. \n",
    "\n",
    "The function will have inputs of `y_true` (np.array) - the true label for a set of samples and `y_pred` (np.array) - the predicted labels for a set of samples, and a threshold `thres_value` (float). \n",
    "\n",
    "The function returns a list of the true positive rate, false positive rate, accuracy and MCC for the inputs where the predicted labels are thresholded at the provided value (using >= comparisons). \n",
    "\n",
    "\n",
    "This function will then be used to create a DataFrames  with rows corresponding with the 10 thresholds (y_pred values) and columns reporting the different thresholds, the true positive rate (TPR), false positive rate (FPR), accuracy (ACC), and Matthews correlation coefficient (MCC).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def calc_metrics(y_true, y_pred, thres_value):\n",
    "    # Calculate tpr, fpr, accuracy, and MCC on input\n",
    "    # Input: \n",
    "    #  y_true - sample labels       (np.array)\n",
    "    #  y_pred - sample predictions  (np.array)\n",
    "    #  thres_value - threshold for predictions,  >= \n",
    "    # Return list of tpr, fpr, accuracy, and MCC \n",
    "    \n",
    "    ...\n",
    "    return ...\n",
    "\n",
    "\n",
    "\n",
    "y_true = np.array([1,1,0,1,1,0,1,0,0,0])\n",
    "y_pred = np.array([0.98,0.92,0.85,0.77,0.71,0.64,0.57,0.42,0.34,0.32])\n",
    "\n",
    "\n",
    "perfDF = pd.DataFrame(columns = ['Threshold', 'TPR', 'FPR', 'ACC', 'MCC']) \n",
    "i = 0 \n",
    "for thres in y_pred: \n",
    "    tpr_val, fpr_val, acc_val, mcc_val = calc_metrics(y_true, y_pred, thres)\n",
    "    perfDF.loc[i] = [thres, tpr_val, fpr_val, acc_val, mcc_val]\n",
    "    i = i+1\n",
    "\n",
    "perfDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "# Q5 - Plot ROC Curve:\n",
    "\n",
    "Use the results from Question 4 to plot the ROC curve for the data. \n",
    "\n",
    "Note, plot this curve using the standard plotting tools rather than any special library/package available for making ROC plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a ROC curve using the results from Q4\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# Q6 - NBA Rookies\n",
    "\n",
    "For this problem you will use a data set of rookie NBA players from 1980 - 2017 seasons.  The dataset was collected from the NBA website API - https://www.nba.com. \n",
    "\n",
    "You will use the data from their rookie year to predict whether a player will last at least 5 seasons in the leaque. \n",
    "\n",
    "The data consists of variables:\n",
    "\n",
    "* `PlayerID`, `Player` - variables to identify individual samples (ignore for prediction)\n",
    "* `Tm`, `Year` - variables describing the year the player started and for what team (ignore for prediction)  \n",
    "* `TARGET` - This is the target / class feature to be predicted (whether the player was in the league for at least 5 years). \n",
    "\n",
    "The remaining variables are predictor variables for the models.  They come in pairs \"*\\_DIFF\" and \"*\\_A\" reporting the given statistic as the difference between Team A and Team B and the statistic itself for Team A. \n",
    "\n",
    "* `Pos` - position of the player, power forward, point guard, shooting guard, center, etc.\n",
    "* `Age` - player age\n",
    "* `G` - sum of number of games played\n",
    "* `GS` - sum of number of games started\n",
    "* `MP` - sum of number of minutes played\n",
    "* `PTS` - sum of number of points scored\n",
    "* `FG` - sum of number of field goals made (both 2 and 3 pointers)\n",
    "* `FGA` - sum of number of field goals attempted\n",
    "* `FG%` - FG / FGA, percentage of field goals made \n",
    "* `3P` - sum of the number of 3 pointers made\n",
    "* `3PA` - sum of the number of 3 pointers attempted\n",
    "* `3P%` - 3P / 3PA, percentage of 3 pointers made\n",
    "* `2P` - sum of the number of 2 point shots made\n",
    "* `2PA` - sum of the number of 2 point shots attempted\n",
    "* `2P%` - 2P / 2PA, percentage of 2 point shots made\n",
    "* `eFG%` - Effective Field Goal Percentage, (`FG` + 0.5 * `3P`)/`FGA`\n",
    "* `FT` - sum of the number of free throws made\n",
    "* `FTA` - sum of the number of free throws attempted\n",
    "* `FT%` - FT / FTA, percentage of free throws made\n",
    "* `ORB` - sum of the number of offensive rebounds\n",
    "* `DRB` - sum of the number of defensive rebounds\n",
    "* `TRB` - sum of the number of total rebounds\n",
    "* `AST` - sum of the number of assists\n",
    "* `STL` - sum of the number of steals\n",
    "* `BLK` - sum of the number of blocks\n",
    "* `TOV` - sum of the number of turnovers\n",
    "* `PF` - sum of the number of personal fouls\n",
    "\n",
    "More information on the stats used can be found: https://www.nba.com/stats/help/glossary   \n",
    "*Note, some of the abbreviations used here are slightly different* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## Q6(a) - Load Data \n",
    "\n",
    "Load the `nba` data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nba = pd.read_csv(...) \n",
    "\n",
    "nba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Q6(b) - Missing Data \n",
    "\n",
    "Let's investigate any missing values in the nba data. \n",
    "\n",
    "First, calculate and report the percentage of missing data for that variable (percentage of rows) in a DataSeries, `miss_nba`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "miss_nba = ... \n",
    "\n",
    "miss_nba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore where these missing values you in the following code cell. \n",
    "\n",
    "**BE SURE TO COMMENT OUT YOUR CODE BEFORE SUBMITTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore where the missing values are in your data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Q6(c) - Handle missing data\n",
    "\n",
    "By investigating where the missing data is, I hope you discovered the following: \n",
    "\n",
    "The missing values reside in two main types of columns (and for two different reasons):\n",
    "* `GS` the game started column has missing values for almost all rookies in the 1980 and 1981 seasons with a few exceptions, e.g., Larry Bird, Clint Richardson, etc.\n",
    "* Columns that calculate a percentage, `FG%`, `3P%`, `2P%`, `eFG%`, `FT%`\n",
    "Here the missing values are due to a divide by zero.\n",
    "\n",
    "Due to the different reasons for the data missing values will be handled differently in each situation. \n",
    "\n",
    "First, the missing values for `GS`, because there is not way to impute these values (and there are so few players in the 1980 and 1981 season having this information), the **all** samples from these two seasons should be deleted. \n",
    "\n",
    "For the missing values in the \"percentage\" columns, replace those missing values with 0. \n",
    "\n",
    "Call you new DataFrame after performing these operations `nba2`.\n",
    "\n",
    "\n",
    "*Note* There may be situations where how you handle missing data (in particular, using imputation methods) should be done in the workflow/pipeline after already splitting for training/testing data in order to avoid possible data leakage.  However, the methods we employ here for dealing the the missing data are not using global properties to perform the imputation, therefore can be done at this state of the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nba2 = ... \n",
    "\n",
    "nba2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Q6(d) - Labels \n",
    "\n",
    "Let's understand the what we should expect as a baseline performance for predicting whether the rookie play remains in the league for at least 5 years. \n",
    "\n",
    "(i). What fraction of players have a positive target label (in the league for at least 5 years)? Value should be in between 0 and 1.  \n",
    "(ii).  What should a constant classifier model predict?   A *constant classifier* always predicts the same value no matter the input.   \n",
    "(iii).  What is the error rate of the constant classifier? Value should be in between 0 and 1. \n",
    "\n",
    "Answer the following questions below.  Note, you should not use any `sklearn` functions, but simply look at properties of the data labels. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "q6d_i = ...\n",
    "\n",
    "q6d_ii = ...\n",
    "\n",
    "q6d_iii = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Q6(e) - Prepare the data \n",
    "\n",
    "At this point, we need to set up the data in order to be used in the classification models. \n",
    "\n",
    "We want to create a DataFrame `nbaX` for the predictor variables and `nbaY` for the target variable. \n",
    "\n",
    "The target variable, `nbaY` will just be the `Target` column of the `nba2` data set. \n",
    "\n",
    "The predictor variables have more considerations. \n",
    "\n",
    "We want to exclude player information such as IDs, `PlayerID` and names `Player`, that are identifying and not predictive.   \n",
    "\n",
    "You should also exclude these other factors (note, that some of these variables may in fact be predictive but we are going to exclude at this time): \n",
    "\n",
    "* `POS` - player position\n",
    "* `Tm` - team\n",
    "* `Year` - rookie year\n",
    "\n",
    "Finally, several of the numeric predictive variables are not only related, but can be directly calculated from one another, e.g., `FG%` = `FG` / `FGA`.  Having variables that are closely related, or in this case redundant may actually hinder the predictive models. \n",
    "\n",
    "Therefore, exclude the following variables: `FG`, `3P`, `2P`, `eFG%`, `FT`, `TRB`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nbaY = ...\n",
    "nbaX = ...\n",
    "\n",
    "print(nbaX.shape)\n",
    "print(nbaY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Q6(f) - Model Selection and Evaluation: Three-fold Split\n",
    "\n",
    "Split the data into training, validation and test sets with 60, 20, and 20% of the data respectively. Make sure to split the data such that the distribution of class labels is approximately equal across splits - “stratify”.\n",
    "\n",
    "Set the seed for the random generator in `random_state` to ”4821”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split of the test set\n",
    "X_trainval, X_test, y_trainval, y_test = ...\n",
    "\n",
    "# Split trainval into train + val \n",
    "X_train, X_val, y_train, y_val = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Q6(g) - Scaling \n",
    "\n",
    "Scale the predictor data with standard scaling (Gaussian normalizaiton). \n",
    "\n",
    "Make sure to use training data set to set scaling parameters and apply those parameters to scaling the training and validation data.\n",
    "\n",
    "Use the train+val to scale the train+val data, and use those parameters to scale the test data to evaluate the best model. \n",
    "\n",
    "Helpful functions: Python - `StandardScaler` from `sklearn.preprocessing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = ...\n",
    "X_train_sc = ...\n",
    "X_val_sc = ...\n",
    "\n",
    "scaler_final = ...\n",
    "X_trainval_sc = ...\n",
    "X_test_sc = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Q6(h) -  KNN - K Nearest Neighbors\n",
    "For values of k, [3, 7, 11, 15, 19, 23, 27, 31], find the best k-nearest-neighbor classifier using the three-fold split of data. \n",
    "\n",
    "* fit a k nearest neighbors model to the training data for each value of k\n",
    "* evaluate the classifier on the training and validation set using AUC\n",
    "* select the best value of k\n",
    "* create a model on train+validation with the *best* value of k \n",
    "* evaluate the classifier on the test data. \n",
    "* plot the training and validation performance vs k;  \n",
    "add a line showing the test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "kvals = [3, 7, 11, 15, 19, 23, 27, 31]\n",
    "\n",
    "knn_auc_val = np.zeros((1,len(kvals)))\n",
    "knn_auc_tr = np.zeros((1,len(kvals)))\n",
    "\n",
    "\n",
    "# fit a k nearest neighbors model to the training data\n",
    "# evaluate the classifier on the training and validation set using auc\n",
    "\n",
    "\n",
    "# select the best value of k\n",
    "knn_bestk = ...\n",
    "\n",
    "# create a best model on train+validation\n",
    "\n",
    "# evaluate the classifier on the test data.\n",
    "knn_auc_test = ...\n",
    "\n",
    "# plot the training and validationing performance vs k.\n",
    "#   add a line for test performance \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Best k:  %d' % (knn_bestk))\n",
    "print('Test Perf:  %.6f' % (knn_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Q6(i) - Decision Trees\n",
    "\n",
    "For values of max_leaf_nodes nodes [5, 10, 25, 50, 75, 100], fit the Decision Trees classifier to the training data. \n",
    "\n",
    "- fit a decision tree model to the training data (use `random_state=4821`) for each of the max_leaf_nodes values\n",
    "- evaluate the classifier on the training and validation set using AUC\n",
    "- select the best max_leaf_nodes\n",
    "- retrain the a model on train+validation with the *best* value of max_leaf_nodes \n",
    "- report the auc on the testing data.\n",
    "- plot the train and validation AUC vs max_leaf_nodes;  \n",
    "add a line for the test AUC performance \n",
    "- print out the best tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "nodes = [5, 10, 25, 50, 75, 100, 150]\n",
    "\n",
    "dt_auc_val = np.zeros((1,len(nodes)))\n",
    "dt_auc_tr = np.zeros((1,len(nodes)))\n",
    "\n",
    "# fit a decision tree model to the training data (use random_state=4821)\n",
    "# evaluate the classifier on the training and validation set using auc\n",
    "\n",
    "\n",
    "# select the best max_leaf_nodes\n",
    "dt_bestn = ...\n",
    "\n",
    "# retrain the best model on train+validation\n",
    "# report the auc on the testing data.\n",
    "dt_auc_test = ...\n",
    "\n",
    "# plot the train and validation auc vs max_leaf_nodes.\n",
    "#   add a line for test performance \n",
    "\n",
    "\n",
    "print('Best max_leaf_nodes:  %d' % (dt_bestn))\n",
    "print('Test Perf:  %.6f' % (dt_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# print out the tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Q6(j) -  Naive Bayes \n",
    "\n",
    "Train a Gaussian Naive Bayes model on training + validation data and report the training+val and testing data performance (auc). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# q6j\n",
    "\n",
    "nb_auc_trainval = ...\n",
    "nb_auc_test = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6j\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "**NOTE** the submission must be run on the campus linux machines.  See the instruction in the Canvas assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-cs4821] *",
   "language": "python",
   "name": "conda-env-.conda-cs4821-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "a2-4821",
   "tests": {
    "q0": {
     "name": "q0",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> COLAB == False\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> LLM == True | GS == True\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> (q1movies.shape[0] == 646) & (q1movies.shape[1] == 32)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> all(q1movies.columns == ['title', 'title_type', 'genre', 'runtime', 'mpaa_rating', 'studio', 'thtr_rel_year', 'thtr_rel_month', 'thtr_rel_day', 'dvd_rel_year', 'dvd_rel_month', 'dvd_rel_day', 'imdb_rating', 'imdb_num_votes', 'critics_rating', 'critics_score', 'audience_rating', 'audience_score', 'best_pic_nom', 'best_pic_win', 'best_actor_win', 'best_actress_win', 'best_dir_win', 'top200_box', 'director', 'actor1', 'actor2', 'actor3', 'actor4', 'actor5', 'imdb_url', 'rt_url'])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> all(q1movies.iloc[1:5, 6] == [2001, 1996, 1993, 2004])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1c": {
     "name": "q1c",
     "points": [
      2
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> all(miss_data[miss_data > 0].index == ['runtime', 'studio', 'dvd_rel_year', 'dvd_rel_month', 'dvd_rel_day', 'director', 'actor1', 'actor2', 'actor3', 'actor4', 'actor5'])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1d": {
     "name": "q1d",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> movies.shape[0] == 645\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> movies.shape[1] == 32\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> all(movies.iloc[100:110, 3] == [102, 101, 84, 102, 90, 122, 107, 97, 165, 109])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1e": {
     "name": "q1e",
     "points": [
      0.2,
      0.2,
      0.2,
      0.2,
      0.2,
      0.2,
      0.2,
      0.1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type_genre in [1, 2, 3, 4]\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> type_runtime in [1, 2, 3, 4]\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> type_mpaa_rating in [1, 2, 3, 4]\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> type_studio in [1, 2, 3, 4]\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> type_thtr_rel_month in [1, 2, 3, 4]\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> type_imdb_rating in [1, 2, 3, 4]\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> type_audience_score in [1, 2, 3, 4]\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> type_best_pic_win in [1, 2, 3, 4]\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1f": {
     "name": "q1f",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q1f.shape == (5, 2)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1g": {
     "name": "q1g",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> round(q1g_cs_mean, 4) == 57.6341 and round(q1g_r_mean, 4) == 105.8527\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> round(q1g_cs_median, 4) == 61.0 and round(q1g_r_median, 4) == 103.0\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> round(q1g_cs_mode, 4) == 67 and round(q1g_r_mode, 4) == 100.0\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1h": {
     "name": "q1h",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> round(q1h_cs_q1, 4) == 33 and round(q1h_r_q1, 4) == 92.0\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> round(q1h_cs_p37, 4) == 47.28 and round(q1h_r_p37, 4) == 97.0\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> round(q1h_cs_q3, 4) == 83.0 and round(q1h_r_q3, 4) == 116.0\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> round(q1h_cs_p83, 4) == 89.0 and round(q1h_r_p83, 4) == 122.0\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": [
      1,
      2
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.allclose(q2outA, np.array([[0.0, 0.0], [0.17, 0.03225806], [0.2, 1.0], [0.4, 0.20967742], [0.65, 0.4516129], [1.0, 0.53225806]]))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.allclose(q2outBtest, np.array([[0.22, 0.03225806], [0.38, 0.83870968], [0.81, 1.03225806]]))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": [
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.allclose(q3outBtrain, np.array([[-1.20221086, -1.08103207], [-0.69549389, -0.98702928], [-0.60607324, 1.83305438], [-0.00993563, -0.47001394], [0.7352364, 0.23500697], [1.77847723, 0.47001394]]))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": 16,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> perfDF.shape == (10, 5)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> all(perfDF.columns == ['Threshold', 'TPR', 'FPR', 'ACC', 'MCC'])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> all(perfDF['TPR'] == [0.2, 0.4, 0.4, 0.6, 0.8, 0.8, 1.0, 1.0, 1.0, 1.0])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 3
        },
        {
         "code": ">>> all(perfDF['ACC'] == [0.6, 0.7, 0.6, 0.7, 0.8, 0.7, 0.8, 0.7, 0.6, 0.5])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 3
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6a": {
     "name": "q6a",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> nba.shape == (2621, 32)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> all(nba.columns == ['PlayerID', 'Player', 'Pos', 'Age', 'Tm', 'Year', 'G', 'GS', 'MP', 'PTS', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'TARGET'])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> all(nba['TARGET'].value_counts() == [1315, 1306])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6b": {
     "name": "q6b",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> miss_nba.shape == (32,)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all(miss_nba[miss_nba > 0].index == ['GS', 'FG%', '3P%', '2P%', 'eFG%', 'FT%'])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(miss_nba.max(), 23.693246)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(miss_nba.mean(), 1.1756009)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6c": {
     "name": "q6c",
     "points": 6,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> nba2.shape == (2487, 32)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> nba2.isna().sum().sum() == 0\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> any(nba2['Year'].isin([1980, 1981])) == False\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6d": {
     "name": "q6d",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(q6d_i, 0.5058303176)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6e": {
     "name": "q6e",
     "points": [
      2,
      1,
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> nbaX.shape == (2487, 19)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> nbaY.shape == (2487,)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all(nba.columns == ['PlayerID', 'Player', 'Pos', 'Age', 'Tm', 'Year', 'G', 'GS', 'MP', 'PTS', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'TARGET'])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all(nbaY.value_counts() == [1258, 1229])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6f": {
     "name": "q6f",
     "points": 6,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> X_train.shape == (1491, 19) and y_train.shape == (1491,)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> X_val.shape == (498, 19) and y_val.shape == (498,)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> X_test.shape == (498, 19) and y_test.shape == (498,)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6g": {
     "name": "q6g",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(X_train_sc[0][0], 0.117347) and np.isclose(X_train_sc[0][1], -0.5709238)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(X_train_sc[60][10], -0.55316873) and np.isclose(X_train_sc[35][12], 0.537966644)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(X_val_sc[30][4], -0.780257632) and np.isclose(X_val_sc[23][9], -0.35039117)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(X_val_sc[24][14], -0.59249814) and np.isclose(X_val_sc[28][3], -0.67867433)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(X_test_sc[0][0], 1.451343696) and np.isclose(X_test_sc[0][1], 1.545438323)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(X_test_sc[20][1], -0.57512671) and np.isclose(X_test_sc[24][8], 0.695857162)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(X_trainval_sc[0][0], 0.226725226) and np.isclose(X_trainval_sc[40][13], 0.0533794211)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.allclose(X_train_sc.mean(axis=0), [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1.5
        },
        {
         "code": ">>> np.allclose(X_trainval_sc.mean(axis=0), [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6h": {
     "name": "q6h",
     "points": [
      2,
      1,
      2,
      2
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(knn_auc_tr[0][0], 0.840645458) and np.isclose(knn_auc_tr[0][3], 0.751082422)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(knn_auc_val[0][6], 0.741482771) and np.isclose(knn_auc_val[0][3], 0.759533488)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(knn_auc_val[0][0], 0.688830816) and np.isclose(knn_auc_val[0][4], 0.757549361)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> knn_bestk == 15\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6i": {
     "name": "q6i",
     "points": [
      1,
      2,
      2
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(dt_auc_tr[0][0], 0.74117146) and np.isclose(dt_auc_tr[0][5], 0.907029537)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(dt_auc_val[0][1], 0.7454994192) and np.isclose(dt_auc_val[0][4], 0.707365466)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(dt_auc_val[0][3], 0.727497096) and np.isclose(dt_auc_val[0][5], 0.680942702)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6j": {
     "name": "q6j",
     "points": 6,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(nb_auc_trainval, 0.718783433)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(nb_auc_test, 0.7311749903)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
